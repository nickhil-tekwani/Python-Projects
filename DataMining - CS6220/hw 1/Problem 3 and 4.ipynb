{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "The parsers are very different for the two datasets (text vs images) but you are allowed to use a library/package to do so. These being very very popular research datasets, it should be easy to find appropriate parsers. You can try to normalize each column/feature separately with with one of the following ideas. Do not normalize labels. When normalizing a column, make sure to normalize its values across all datapoints (train, test, validation, etc) for consistency\n",
    "\n",
    "Typical options for feature values (normalization optional):\n",
    "- 20NG text row normalization TF(term,doc) / DL (doc). For text is critical to maintain a sparse format due to large number of columns; make sure any value transformation retains the 0 values.\n",
    "- MNIST : since these images are black and white (and some gray) the pixel values are already in a pre-formatted range [0-255]. They may not require normalization, but perhaps its easier to get the values to have 0 mean instead of 128 mean. Depending on what similarity/distance measure you use, computation of similarity might be easy but the size of the similarity matrix might present a challenge.\n",
    "- Shift-and-scale normalization: subtract the minimum, then divide by new maximum. Now all values are between 0-1\n",
    "- Zero mean, unit variance : subtract the mean, divide by the appropriate value to get variance=1\n",
    "\n",
    "Options for distance/similarity. You are encouraged to use your own implementation to compute the pairwise similarity/distance matrix; but we will accept a library available in Matlab/Java/Python/R.\n",
    "- cosine or simple dot product (required)\n",
    "- euclidian distance (required)\n",
    "- editing distance (required)- use a threshold of tolerance on numerical feature values to asess \"the same\"\n",
    "- jaccard similarity(optional)\n",
    "- Manhattan distance(optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import collections\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import mnist \n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset = 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting the vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "count_vectorizer = CountVectorizer()\n",
    "train_tfidf_matrix = tfidf_vectorizer.fit_transform(newsgroups_train.data)\n",
    "train_tf_matrix = count_vectorizer.fit_transform(newsgroups_train.data)\n",
    "test_tfidf_matrix = tfidf_vectorizer.transform(newsgroups_test.data)\n",
    "test_tf_matrix = count_vectorizer.transform(newsgroups_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 130107) (7532, 130107)\n"
     ]
    }
   ],
   "source": [
    "print(train_tf_matrix.shape, test_tf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 130107) (7532, 130107)\n"
     ]
    }
   ],
   "source": [
    "print(train_tfidf_matrix.shape, test_tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of tf sparse matrix: (11314, 130107)\n",
      "The Shape of tf idf sparse matrix: (11314, 130107)\n",
      "The Shape of tf sparse matrix: (7532, 130107)\n",
      "The Shape of tf idf sparse matrix: (7532, 130107)\n"
     ]
    }
   ],
   "source": [
    "print(\"The Shape of tf sparse matrix:\",train_tf_matrix.shape)\n",
    "print(\"The Shape of tf idf sparse matrix:\",train_tfidf_matrix.shape)\n",
    "print(\"The Shape of tf sparse matrix:\",test_tf_matrix.shape)\n",
    "print(\"The Shape of tf idf sparse matrix:\",test_tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row represent the documents and the colunms are word indices. \n",
    "\n",
    "In tf matrix the word frequency per documents is stored in matrix. \n",
    "\n",
    "In tfidf matrix the tfidf (tf * idf) value of each word per document is stored in the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#lets look at some raw data of the sparse matrix\n",
    "print(train_tf_matrix[0:2,0:10].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#lets look at some raw data of the sparse matrix\n",
    "print(train_tfidf_matrix[50:51,0:100].todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparsity is a major challenge while dealing with text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity for Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the relevant library\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The total Running time for computing cosine simlarity of tf matrix in seconds: 12.987414121627808\n"
     ]
    }
   ],
   "source": [
    "#start time \n",
    "start = time.time()\n",
    "\n",
    "#compute the cosine similarity of each doucment with one another\n",
    "ng_tf_cs = cosine_similarity(train_tf_matrix,train_tf_matrix)\n",
    "\n",
    "#end time \n",
    "end = time.time()\n",
    "\n",
    "#total time \n",
    "print(\"\\nThe total Running time for computing cosine simlarity of tf matrix in seconds:\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The total Running time  for computing cosine simlarity of tfidf matrix in seconds: 13.994904041290283\n"
     ]
    }
   ],
   "source": [
    "#start time \n",
    "start = time.time()\n",
    "\n",
    "#compute the cosine similarity of each doucment with one another\n",
    "ng_tfidf_cs = cosine_similarity(train_tfidf_matrix,train_tfidf_matrix)\n",
    "\n",
    "#end time \n",
    "end = time.time()\n",
    "\n",
    "#total time \n",
    "print(\"\\nThe total Running time  for computing cosine simlarity of tfidf matrix in seconds:\",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity for Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The total Running time for computing cosine simlarity of tf matrix in seconds: 8.332358837127686\n"
     ]
    }
   ],
   "source": [
    "#start time \n",
    "start = time.time()\n",
    "\n",
    "#compute the cosine similarity of each doucment with one another\n",
    "ng_test_tf_cs = cosine_similarity(test_tf_matrix,train_tf_matrix)\n",
    "\n",
    "#end time \n",
    "end = time.time()\n",
    "\n",
    "#total time \n",
    "print(\"\\nThe total Running time for computing cosine simlarity of tf matrix in seconds:\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The total Running time for computing cosine simlarity of tf matrix in seconds: 8.42072606086731\n"
     ]
    }
   ],
   "source": [
    "#start time \n",
    "start = time.time()\n",
    "\n",
    "#compute the cosine similarity of each doucment with one another\n",
    "ng_test_tfidf_cs = cosine_similarity(test_tfidf_matrix,train_tfidf_matrix)\n",
    "\n",
    "#end time \n",
    "end = time.time()\n",
    "\n",
    "#total time \n",
    "print(\"\\nThe total Running time for computing cosine simlarity of tf matrix in seconds:\",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Distance for Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the relevant library\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The total Running time for computing similarity by euclidean distance of tf matrix in seconds: 14.707864046096802\n"
     ]
    }
   ],
   "source": [
    "#start time \n",
    "start = time.time()\n",
    "\n",
    "#compute the cosine similarity of each doucment with one another\n",
    "ng_tf_ed = euclidean_distances(train_tf_matrix)\n",
    "\n",
    "#end time \n",
    "end = time.time()\n",
    "\n",
    "#total time \n",
    "print(\"\\nThe total Running time for computing similarity by euclidean distance of tf matrix in seconds:\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The total Running time for similarity by euclidean distance of tfidf matrix in seconds: 14.818179845809937\n"
     ]
    }
   ],
   "source": [
    "#start time \n",
    "start = time.time()\n",
    "\n",
    "#compute the cosine similarity of each doucment with one another\n",
    "ng_tfidf_ed = euclidean_distances(train_tfidf_matrix)\n",
    "\n",
    "#end time \n",
    "end = time.time()\n",
    "\n",
    "#total time \n",
    "print(\"\\nThe total Running time for similarity by euclidean distance of tfidf matrix in seconds:\",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean distances for Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The total Running time for computing similarity by euclidean distance of tf matrix in seconds: 9.172903299331665\n"
     ]
    }
   ],
   "source": [
    "#start time \n",
    "start = time.time()\n",
    "\n",
    "#compute the cosine similarity of each doucment with one another\n",
    "ng_test_tf_ed = euclidean_distances(test_tf_matrix,train_tf_matrix)\n",
    "\n",
    "#end time \n",
    "end = time.time()\n",
    "\n",
    "#total time \n",
    "print(\"\\nThe total Running time for computing similarity by euclidean distance of tf matrix in seconds:\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The total Running time for similarity by euclidean distance of tfidf matrix in seconds: 9.743610143661499\n"
     ]
    }
   ],
   "source": [
    "#start time \n",
    "start = time.time()\n",
    "\n",
    "#compute the cosine similarity of each doucment with one another\n",
    "ng_test_tfidf_ed = euclidean_distances(test_tfidf_matrix,train_tfidf_matrix)\n",
    "\n",
    "#end time \n",
    "end = time.time()\n",
    "\n",
    "#total time \n",
    "print(\"\\nThe total Running time for similarity by euclidean distance of tfidf matrix in seconds:\",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Vectorizing the text data into a sparse matrix\n",
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data).toarray()\n",
    "\n",
    "# Creating an array to store the edit distances\n",
    "edit_distances = np.zeros((len(vectors), len(vectors)))\n",
    "\n",
    "# Computing the edit distance for each pair of documents\n",
    "for i in range(len(vectors)):\n",
    "    for j in range(i, len(vectors)):\n",
    "        distance = levenshtein_distance(vectors[i], vectors[j])\n",
    "        edit_distances[i, j] = distance\n",
    "        edit_distances[j, i] = distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy 0.9165635495845855\n"
     ]
    }
   ],
   "source": [
    "#accuracy on training data using cosine similarity and tfidf vector\n",
    "k = 5\n",
    "sum = 0\n",
    "for i in range(0,len(newsgroups_train.data)):\n",
    "    similar_index =  np.argsort(ng_tfidf_cs[i])[:-(k+1):-1].tolist()\n",
    "    l = newsgroups_train.target[similar_index].tolist()\n",
    "    label = max(l,key=l.count)\n",
    "    actual_label = newsgroups_train.target[i]\n",
    "    if label == actual_label:\n",
    "        sum += 1\n",
    "print(\"training accuracy\",sum/len(newsgroups_train.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy 0.8680395969595192\n"
     ]
    }
   ],
   "source": [
    "#accuracy on training data using cosine similarity and tfidf vector\n",
    "k = 10\n",
    "sum = 0\n",
    "for i in range(0,len(newsgroups_train.data)):\n",
    "    similar_index =  np.argsort(ng_tfidf_cs[i])[:-(k+1):-1].tolist()\n",
    "    l = newsgroups_train.target[similar_index].tolist()\n",
    "    label = max(l,key=l.count)\n",
    "    actual_label = newsgroups_train.target[i]\n",
    "    if label == actual_label:\n",
    "        sum += 1\n",
    "print(\"training accuracy\",sum/len(newsgroups_train.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy 0.8656531730599257\n"
     ]
    }
   ],
   "source": [
    "#accuracy on training data using cosine similarity and tf vector\n",
    "k = 5\n",
    "sum = 0\n",
    "for i in range(0,len(newsgroups_train.data)):\n",
    "    similar_index =  np.argsort(ng_tf_cs[i])[:-(k+1):-1].tolist()\n",
    "    l = newsgroups_train.target[similar_index].tolist()\n",
    "    label = max(l,key=l.count)\n",
    "    actual_label = newsgroups_train.target[i]\n",
    "    if label == actual_label:\n",
    "        sum += 1\n",
    "print(\"training accuracy\",sum/len(newsgroups_train.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy 0.9165635495845855\n"
     ]
    }
   ],
   "source": [
    "#accuracy on training data using euclidean distances and tfidf vector\n",
    "k = 5\n",
    "sum = 0\n",
    "for i in range(0,len(newsgroups_train.data)):\n",
    "    similar_index =  np.argsort(ng_tfidf_ed[i])[:k].tolist()\n",
    "    l = newsgroups_train.target[similar_index].tolist()\n",
    "    label = max(l,key=l.count)\n",
    "    actual_label = newsgroups_train.target[i]\n",
    "    if label == actual_label:\n",
    "        sum += 1\n",
    "print(\"training accuracy\",sum/len(newsgroups_train.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy 0.8793530139649991\n"
     ]
    }
   ],
   "source": [
    "#accuracy on training data using euclidean distances and tf vector\n",
    "k = 5\n",
    "sum = 0\n",
    "for i in range(0,len(newsgroups_train.data)):\n",
    "    similar_index =  np.argsort(ng_tf_ed[i])[:k].tolist()\n",
    "    l = newsgroups_train.target[similar_index].tolist()\n",
    "    label = max(l,key=l.count)\n",
    "    actual_label = newsgroups_train.target[i]\n",
    "    if label == actual_label:\n",
    "        sum += 1\n",
    "print(\"training accuracy\",sum/len(newsgroups_train.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy 0.6755177907594264\n"
     ]
    }
   ],
   "source": [
    "#accuracy on test data using cosine similarity and tfidf vector\n",
    "k = 5\n",
    "sum = 0\n",
    "for i in range(0,len(newsgroups_test.data)):\n",
    "    similar_index =  np.argsort(ng_test_tfidf_cs[i])[:-(k+1):-1].tolist()\n",
    "    l = newsgroups_train.target[similar_index].tolist()\n",
    "    label = max(l,key=l.count)\n",
    "    actual_label = newsgroups_test.target[i]\n",
    "    if label == actual_label:\n",
    "        sum += 1\n",
    "print(\"training accuracy\",sum/len(newsgroups_test.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy 0.4305629314922995\n"
     ]
    }
   ],
   "source": [
    "#accuracy on test data using cosine similarity and tf vector\n",
    "k = 5\n",
    "sum = 0\n",
    "for i in range(0,len(newsgroups_test.data)):\n",
    "    similar_index =  np.argsort(ng_test_tf_cs[i])[:-(k+1):-1].tolist()\n",
    "    l = newsgroups_train.target[similar_index].tolist()\n",
    "    label = max(l,key=l.count)\n",
    "    actual_label = newsgroups_test.target[i]\n",
    "    if label == actual_label:\n",
    "        sum += 1\n",
    "print(\"training accuracy\",sum/len(newsgroups_test.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy 0.6755177907594264\n"
     ]
    }
   ],
   "source": [
    "#accuracy on test data using euclidean distances and tfidf vector\n",
    "k = 5\n",
    "sum = 0\n",
    "for i in range(0,len(newsgroups_test.data)):\n",
    "    similar_index =  np.argsort(ng_test_tfidf_ed[i])[:k].tolist()\n",
    "    l = newsgroups_train.target[similar_index].tolist()\n",
    "    label = max(l,key=l.count)\n",
    "    actual_label = newsgroups_test.target[i]\n",
    "    if label == actual_label:\n",
    "        sum += 1\n",
    "print(\"training accuracy\",sum/len(newsgroups_test.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy 0.38382899628252787\n"
     ]
    }
   ],
   "source": [
    "#accuracy on test data using euclidean distances and tf vector\n",
    "k = 5\n",
    "sum = 0\n",
    "for i in range(0,len(newsgroups_test.data)):\n",
    "    similar_index =  np.argsort(ng_test_tf_ed[i])[:k].tolist()\n",
    "    l = newsgroups_train.target[similar_index].tolist()\n",
    "    label = max(l,key=l.count)\n",
    "    actual_label = newsgroups_test.target[i]\n",
    "    if label == actual_label:\n",
    "        sum += 1\n",
    "print(\"training accuracy\",sum/len(newsgroups_test.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8665, 4772, 9080, 2931, 4495]\n",
      "[2, 2, 2, 2, 2]\n",
      "comp.os.ms-windows.misc\n",
      "comp.os.ms-windows.misc\n",
      "comp.os.ms-windows.misc\n",
      "comp.os.ms-windows.misc\n",
      "comp.os.ms-windows.misc\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#Print labels\n",
    "similar_index = np.argsort(ng_test_tf_cs[123])[:5].tolist()\n",
    "print(similar_index)\n",
    "l = newsgroups_train.target[similar_index].tolist()\n",
    "print(l)\n",
    "for i in l :\n",
    "    print(newsgroups_train.target_names[i])\n",
    "label = max(l,key=l.count)\n",
    "print(label)\n",
    "actual_label = newsgroups_train.target[i]\n",
    "print(actual_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "####  Train and test KNN classification (supervised)\n",
    "\n",
    "Some datasets might come organized into train/test in which case we respect that. Other datasets come without this organization in which case we randomly (\"random\" here is very important, data must be shuffled) pick about 80% of data as training , 10% as validation (also used in training) and 10% as testing data (completely unavailable to training)\n",
    "\n",
    "For each of the two datasets, now in matrix format and with pairwise similarity computed, train and test KNN classification. Report both training performance and testing performance. You are required to implement KNN yourself, but can youse suport libraries and data-structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mndata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m     35\u001b[0m mnist \u001b[38;5;241m=\u001b[39m fetch_openml(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist_784\u001b[39m\u001b[38;5;124m'\u001b[39m, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mmndata\u001b[49m\u001b[38;5;241m.\u001b[39mload_training()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# The MNIST dataset loaded via the mnist package is a list, convert it to numpy arrays\u001b[39;00m\n\u001b[1;32m     39\u001b[0m images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(images)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mndata' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        predicted_labels = [self._predict(x) for x in X]\n",
    "        return np.array(predicted_labels)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        # Compute distances between x and all examples in the training set\n",
    "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        # Sort by distance and return indices of the first k neighbors\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        # Extract the labels of the k nearest neighbor training samples\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        # return the most common class label\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2)**2))\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "images, labels = mndata.load_training()\n",
    "\n",
    "# The MNIST dataset loaded via the mnist package is a list, convert it to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Rescale the images data to values between 0 and 1\n",
    "images = images / 255.0\n",
    "\n",
    "# Now your previous code should work\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=1234)\n",
    "knn = KNN(k=3)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Print accuracy\n",
    "print(\"KNN Test Accuracy: \", np.sum(predictions == y_test) / len(y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
